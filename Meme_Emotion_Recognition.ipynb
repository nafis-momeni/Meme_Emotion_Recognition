{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "suLl8eNKkVZX",
        "rD49NIe9loqe",
        "aaZv2D3TPJ7l",
        "LBEwtp8Y4Vip",
        "xTOZwrPLfOJP"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers keras==2.12.0"
      ],
      "metadata": {
        "id": "HSF8GR1B0cbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# General Python and file-related libraries\n",
        "import os\n",
        "import re\n",
        "import h5py\n",
        "import pprint\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio\n",
        "import PIL\n",
        "from PIL import ImageFile\n",
        "import cv2\n",
        "from tqdm import tqdm_notebook\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "# TensorFlow and Keras libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Dense, Embedding, LSTM, Dropout, Bidirectional, GRU,\n",
        "    Conv2D, MaxPooling2D, Flatten, concatenate, GlobalAveragePooling2D, BatchNormalization,\n",
        "    Lambda, Add, Multiply\n",
        ")\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Hugging Face Transformers library\n",
        "from transformers import *\n",
        "\n",
        "# Suppressing PIL warnings\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n"
      ],
      "metadata": {
        "id": "qsQOczd9k7w4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading and Processing Data"
      ],
      "metadata": {
        "id": "c0zX5CxBPfYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "w6o2Aqi6WGGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Text"
      ],
      "metadata": {
        "id": "VP4a3fyQPjT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train=pd.read_csv('/content/drive/My Drive/Memotion/SemEval-2020-Task-8/train.csv')\n",
        "val=pd.read_csv('/content/drive/My Drive/Memotion/SemEval-2020-Task-8/val.csv')\n",
        "test=pd.read_csv('/content/drive/My Drive/Memotion/SemEval-2020-Task-8/test.csv')\n",
        "print(train.shape)\n",
        "print(val.shape)\n",
        "print(test.shape)\n",
        "\n",
        "# output:\n",
        "# (5943, 8)\n",
        "# (1049, 8)\n",
        "# (1878, 4)\n"
      ],
      "metadata": {
        "id": "_V6PeOTFWWq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train=train.iloc[:,[2,7,0]]\n",
        "data_val=val.iloc[:,[2,7,0]]\n",
        "data_train.columns=[0,1,2]\n",
        "data_val.columns=[0,1,2]\n",
        "data_test=test.loc[:,['corrected_text','Image_URL','Image_name']]"
      ],
      "metadata": {
        "id": "0BUQGlsxuzpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def process(data):\n",
        "  for i in tqdm(range(data.shape[0])):\n",
        "    eg=re.sub('[^a-zA-Z]',' ',data.iloc[i,0])\n",
        "    #eg=re.sub('(?!^)([A-Z][a-z]+)', r' \\1', eg).lower()\n",
        "    #eg=re.sub(r'^\"|\"$', '', eg)\n",
        "    eg=\" \".join(eg.lower().split())\n",
        "    #eg=eg.split()\n",
        "    #ps=PorterStemmer()\n",
        "    #eg=[word for word in eg if not word in set(stopwords.words('english'))]\n",
        "    #eg=\" \".join(eg)\n",
        "\n",
        "    data.iloc[i,0]=eg\n",
        "  return data\n",
        "\n",
        "\n",
        "data_train=process(data_train.copy())\n",
        "data_val=process(data_val.copy())\n",
        "data_test=process(data_test.copy())"
      ],
      "metadata": {
        "id": "d2s9Xo4Ovpuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#change the lables to 0,1 for binary classification for simpicity\n",
        "\n",
        "for i in range(train.shape[0]):\n",
        "  if train.iloc[i,3]=='hilarious':\n",
        "    train.iloc[i,3]=1\n",
        "  if train.iloc[i,3]=='very_funny':\n",
        "    train.iloc[i,3]=1\n",
        "  if train.iloc[i,3]=='funny':\n",
        "    train.iloc[i,3]=1\n",
        "  if train.iloc[i,3]=='not_funny':\n",
        "    train.iloc[i,3]=0\n",
        "\n",
        "  if train.iloc[i,4]=='very_twisted':\n",
        "    train.iloc[i,4]=1\n",
        "  if train.iloc[i,4]=='twisted_meaning':\n",
        "    train.iloc[i,4]=1\n",
        "  if train.iloc[i,4]=='general':\n",
        "    train.iloc[i,4]=1\n",
        "  if train.iloc[i,4]=='not_sarcastic':\n",
        "    train.iloc[i,4]=0\n",
        "\n",
        "  if train.iloc[i,5]=='hateful_offensive':\n",
        "    train.iloc[i,5]=1\n",
        "  if train.iloc[i,5]=='very_offensive':\n",
        "    train.iloc[i,5]=1\n",
        "  if train.iloc[i,5]=='slight':\n",
        "    train.iloc[i,5]=1\n",
        "  if train.iloc[i,5]=='not_offensive':\n",
        "    train.iloc[i,5]=0\n",
        "\n",
        "  if train.iloc[i,6]=='motivational':\n",
        "    train.iloc[i,6]=1\n",
        "  if train.iloc[i,6]=='not_motivational':\n",
        "    train.iloc[i,6]=0\n",
        "\n",
        "for i in range(val.shape[0]):\n",
        "  if val.iloc[i,3]=='hilarious':\n",
        "    val.iloc[i,3]=1\n",
        "  if val.iloc[i,3]=='very_funny':\n",
        "    val.iloc[i,3]=1\n",
        "  if val.iloc[i,3]=='funny':\n",
        "    val.iloc[i,3]=1\n",
        "  if val.iloc[i,3]=='not_funny':\n",
        "    val.iloc[i,3]=0\n",
        "\n",
        "  if val.iloc[i,4]=='very_twisted':\n",
        "    val.iloc[i,4]=1\n",
        "  if val.iloc[i,4]=='twisted_meaning':\n",
        "    val.iloc[i,4]=1\n",
        "  if val.iloc[i,4]=='general':\n",
        "    val.iloc[i,4]=1\n",
        "  if val.iloc[i,4]=='not_sarcastic':\n",
        "    val.iloc[i,4]=0\n",
        "\n",
        "  if val.iloc[i,5]=='hateful_offensive':\n",
        "    val.iloc[i,5]=1\n",
        "  if val.iloc[i,5]=='very_offensive':\n",
        "    val.iloc[i,5]=1\n",
        "  if val.iloc[i,5]=='slight':\n",
        "    val.iloc[i,5]=1\n",
        "  if val.iloc[i,5]=='not_offensive':\n",
        "    val.iloc[i,5]=0\n",
        "\n",
        "  if val.iloc[i,6]=='motivational':\n",
        "    val.iloc[i,6]=1\n",
        "  if val.iloc[i,6]=='not_motivational':\n",
        "    val.iloc[i,6]=0"
      ],
      "metadata": {
        "id": "9u_8AobMyoVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "humour_distribution = train['humour'].value_counts()\n",
        "sarcasm_distribution = train['sarcasm'].value_counts()\n",
        "offensive_distribution = train['offensive'].value_counts()\n",
        "offensive_distribution_val = val['offensive'].value_counts()\n",
        "motivational_distribution = train['motivational'].value_counts()\n",
        "\n",
        "# Display the distributions\n",
        "print(\"Distribution of 'humour' column:\")\n",
        "print(humour_distribution)\n",
        "\n",
        "# print(\"\\nDistribution of 'sarcasm' column:\")\n",
        "# print(sarcasm_distribution)\n",
        "\n",
        "print(\"\\nDistribution of 'offensive' column:\")\n",
        "print(offensive_distribution)\n",
        "\n",
        "print(\"\\nDistribution of 'offensive val' column:\")\n",
        "print(offensive_distribution_val)\n",
        "\n",
        "# print(\"\\nDistribution of 'motivational' column:\")\n",
        "# print(motivational_distribution)"
      ],
      "metadata": {
        "id": "Ldbv29R0QB8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cls='motivational' #possible values : humour\tsarcasm\toffensive\tmotivational\n",
        "data_train[1]=train[cls]\n",
        "data_val[1]=val[cls]\n",
        "\n",
        "\n",
        "class_labels = tf.convert_to_tensor(data_train.iloc[:,1], dtype=tf.int64)\n",
        "class_labels_val = tf.convert_to_tensor(data_val.iloc[:,1], dtype=tf.int64)\n"
      ],
      "metadata": {
        "id": "CZ52Ov04m9z8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kcjnm0JojnS6"
      },
      "source": [
        "Upsampling Data to handle class imbalance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSdxtOE7j27c"
      },
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "UpSample=True\n",
        "\n",
        "if UpSample:\n",
        "  X,Y=RandomOverSampler(random_state=42).fit_resample(data_train.iloc[:,[0,2]],class_labels)\n",
        "  data_train=pd.concat((pd.DataFrame(X),pd.DataFrame(Y)),axis=1)\n",
        "  X,Y=RandomOverSampler(random_state=42).fit_resample(data_val.iloc[:,[0,2]],class_labels_val)\n",
        "  data_val=pd.concat((pd.DataFrame(X),pd.DataFrame(Y)),axis=1)\n",
        "  data_train.columns=['text','image','class']\n",
        "  data_val.columns=['text','image','class']\n",
        "  data_test.columns=['text','waste','image']\n",
        "  data_train\n",
        "\n",
        "else:\n",
        "  X,Y=RandomOverSampler(random_state=42).fit_resample(data_val.iloc[:,[0,2]],class_labels_val)\n",
        "  data_val=pd.concat((pd.DataFrame(X),pd.DataFrame(Y)),axis=1)\n",
        "  data_train.columns=['text','class','image']\n",
        "  data_val.columns=['text','image','class']\n",
        "  data_test.columns=['text','waste','image']\n",
        "  data_train\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "offensive_distribution = data_train['class'].value_counts()\n",
        "offensive_distribution_val = data_val['class'].value_counts()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\nDistribution of 'offensive' column:\")\n",
        "print(offensive_distribution)\n",
        "\n",
        "print(\"\\nDistribution of 'offensive val' column:\")\n",
        "print(offensive_distribution_val)\n"
      ],
      "metadata": {
        "id": "tfJhO9QZQtI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image"
      ],
      "metadata": {
        "id": "6aFmCluDPrqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp '/content/drive/My Drive/Memotion/kaggle.json' ~/.kaggle/\n",
        "\n",
        "!kaggle datasets download --unzip williamscott701/memotion-dataset-7k\n",
        "# !rsync --info=progress2 '/content/drive/My Drive/Memotion/2000_data.zip' '/content/'\n",
        "# !unzip '/content/2000_data.zip'"
      ],
      "metadata": {
        "id": "r6rG_HNzPurJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UniModal"
      ],
      "metadata": {
        "id": "bTzEED4jlyBR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BiLSTM"
      ],
      "metadata": {
        "id": "suLl8eNKkVZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tk = Tokenizer(lower = True)\n",
        "tk.fit_on_texts(data_train.text.values)\n",
        "\n",
        "X_train_seq = tk.texts_to_sequences(data_train.text.values)\n",
        "X_val_seq = tk.texts_to_sequences(data_val.text.values)\n",
        "X_train = pad_sequences(X_train_seq, maxlen=64, padding='post')\n",
        "X_val = pad_sequences(X_val_seq, maxlen=64, padding='post')\n",
        "X_test_seq = tk.texts_to_sequences(data_test.text.values)\n",
        "X_test = pad_sequences(X_test_seq, maxlen=64, padding='post')"
      ],
      "metadata": {
        "id": "8oRIHURq1yB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = data_train['class'].copy()\n",
        "y_val = data_val['class'].copy()\n",
        "y_train = y_train.astype(float)\n",
        "y_val = y_val.astype(float)"
      ],
      "metadata": {
        "id": "knn1SjmpXklQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLaXixtz1ly-"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Compute class weights for the specified class\n",
        "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "\n",
        "class_weights= {0:class_weights[0],1:class_weights[1]}\n",
        "\n",
        "Batch_size = 64\n",
        "vocabulary_size = len(tk.word_counts.keys())+1\n",
        "max_words = 64\n",
        "embedding_size = 64\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words,))\n",
        "model.add(Dropout(0))\n",
        "\n",
        "model.add(Bidirectional(LSTM(32)))\n",
        "model.add(Dropout(0))\n",
        "model.add(Dense(1, activation='softmax'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "\n",
        "early=EarlyStopping(patience=3, restore_best_weights=True, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.01, patience=3, verbose=1)\n",
        "\n",
        "\n",
        "history=model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=Batch_size,\n",
        "          epochs=50,\n",
        "          class_weight=class_weights,\n",
        "          callbacks=[early,reduce_lr]\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYy3z_dq7eYO"
      },
      "outputs": [],
      "source": [
        "y_train_prob=model.predict(X_train)\n",
        "y_val_prob=model.predict(X_val)\n",
        "\n",
        "y_train_pred = [1 if x>0.5 else 0 for x in y_train_prob]\n",
        "y_val_pred = [1 if x>0.5 else 0 for x in y_val_prob]\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix,auc\n",
        "\n",
        "print(\"Training Accuracy : {0}%\".format(int(100*accuracy_score(y_train, y_train_pred))))\n",
        "print(\"test Accuracy : {0}%\\n\".format(int(100*accuracy_score(y_val, y_val_pred))))\n",
        "print(classification_report(y_val, y_val_pred))\n",
        "\n",
        "confusion = confusion_matrix(y_val, y_val_pred)\n",
        "print(confusion)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##RoBERTa"
      ],
      "metadata": {
        "id": "rD49NIe9loqe"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmwIWImrj-DK"
      },
      "source": [
        "Setting maximum sequence length for the inputs to RoBERTa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eHXS4p6j6yH"
      },
      "source": [
        "max_seq_length=0\n",
        "for i in tqdm(range(data_train.shape[0])):\n",
        "    max_seq_length=max(len(data_train.iloc[i,0].split()),max_seq_length)\n",
        "max_seq_length=max_seq_length+2\n",
        "print(max_seq_length)\n",
        "\n",
        "# output :\n",
        "# 201"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxQc60tekJfC"
      },
      "source": [
        "Textual data processing function to prepare meme overlay text for input to Roberta Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_examples_to_features(sentences, label_list, max_seq_length, tokenizer):\n",
        "    input_ids, input_masks, segment_ids, labels = [], [], [], []\n",
        "    for index in tqdm_notebook(range(len(sentences)), desc=\"Converting examples to features\"):\n",
        "        sentence = sentences[index]\n",
        "        if sentence == '':\n",
        "            sentence = \" \"\n",
        "        # inputs = tokenizer.encode_plus(sentence, max_length=max_seq_length, pad_to_max_length=True)\n",
        "        inputs = tokenizer.encode_plus(\n",
        "            sentence,\n",
        "            add_special_tokens=True,  # Add [CLS] and [SEP] tokens\n",
        "            max_length=max_seq_length,# Specify the maximum length of the tokens\n",
        "            pad_to_max_length=True,   # Pad shorter sequences to max length\n",
        "            return_token_type_ids=True,  # Return segment IDs\n",
        "            return_attention_mask=True,  # Return attention mask\n",
        "          )\n",
        "        input_id = inputs['input_ids']\n",
        "        input_mask = inputs['attention_mask']\n",
        "        segment_id = inputs['token_type_ids']\n",
        "        label = label_list[index]\n",
        "        input_ids.append(input_id)\n",
        "        input_masks.append(input_mask)\n",
        "        segment_ids.append(segment_id)\n",
        "        labels.append(label)\n",
        "    return (\n",
        "        np.array(input_ids),\n",
        "        np.array(input_masks),\n",
        "        np.array(segment_ids),\n",
        "        np.array(labels)\n",
        "    )"
      ],
      "metadata": {
        "id": "aeMDJE5wfJRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PjgTX73kNMH"
      },
      "source": [
        "Processing textual data using above function"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import *\n",
        "tokenizer=RobertaTokenizer.from_pretrained('roberta-base')\n",
        "#tokenizer=AlbertTokenizer.from_pretrained(\"albert-base-v2\")\n",
        "\n",
        "data_train=data_train.reset_index(drop=True)\n",
        "data_val=data_val.reset_index(drop=True)\n",
        "\n",
        "(train_input_ids, train_input_masks, train_segment_ids, train_labels\n",
        ") = convert_examples_to_features(data_train['text'],data_train['class'],max_seq_length,tokenizer)\n",
        "\n",
        "(val_input_ids, val_input_masks, val_segment_ids, val_labels\n",
        ") = convert_examples_to_features(data_val['text'],data_val['class'],max_seq_length,tokenizer)\n",
        "\n",
        "(test_input_ids, test_input_masks, test_segment_ids, test_labels\n",
        ") = convert_examples_to_features(data_test['text'],np.ones(data_test.shape[0]),max_seq_length,tokenizer)\n"
      ],
      "metadata": {
        "id": "TEzcGGitfu3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YpsCUNAkOfd"
      },
      "source": [
        "Defining F1 metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRBEO-a2j_4j"
      },
      "source": [
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    y_pred = K.round(y_pred)\n",
        "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
        "    # tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
        "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
        "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
        "\n",
        "    p = tp / (tp + fp + K.epsilon())\n",
        "    r = tp / (tp + fn + K.epsilon())\n",
        "\n",
        "    f1 = 2*p*r / (p+r+K.epsilon())\n",
        "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
        "    return K.mean(f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6cURBzekapJ"
      },
      "source": [
        "Keras Callbacks to simplify model saving"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NmWfrcukSbo"
      },
      "source": [
        "class Saver(tf.keras.callbacks.Callback):\n",
        "  def on_train_begin(self,logs={}):\n",
        "    self.score=0\n",
        "  def on_epoch_end(self,logs={},*args):\n",
        "    #self.model.save_weights('/media/data_dump/Pradyumna/empha/model-{}-{}-{}-{}-L.h5'.format(lr,epochs,dropout,layers))\n",
        "    predictions=self.model.predict([val_input_ids, val_input_masks, val_segment_ids])\n",
        "    res=f1_score(val_labels,np.argmax(predictions,axis=1),average='macro')\n",
        "    print(\"f1_score=\",res)\n",
        "    if res>self.score:\n",
        "        self.score=res\n",
        "        self.model.save_weights('/content/drive/My Drive/Memotion/model_save_memo/test-2.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOTsFsgLkj-A"
      },
      "source": [
        "Defining model architecture and training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input,Dense,Bidirectional,LSTM\n",
        "from tensorflow.keras.metrics import Precision\n",
        "\n",
        "precision_metric = Precision()\n",
        "\n",
        "# Best hyperparameters\n",
        "lr=1e-5\n",
        "epochs=15\n",
        "layer=2\n",
        "dropout=0\n",
        "\n",
        "\n",
        "\n",
        "token_inputs = tf.keras.layers.Input(shape=(None,), name='word_inputs', dtype=tf.int32)\n",
        "mask_inputs = tf.keras.layers.Input(shape=(None,), name='mask_inputs', dtype=tf.int32)\n",
        "seg_inputs = tf.keras.layers.Input(shape=(None,), name='seg_inputs', dtype=tf.int32)\n",
        "\n",
        "inputs=[token_inputs,mask_inputs,seg_inputs]\n",
        "\n",
        "transformer_outputs= TFRobertaModel.from_pretrained('roberta-base')(inputs)[0][:,0,:]\n",
        "\n",
        "step=transformer_outputs\n",
        "\n",
        "\n",
        "if layer>=3:\n",
        "  step=tf.keras.layers.Dense(512,activation='relu')(step)\n",
        "  if dropout!=0:\n",
        "      step=tf.keras.layers.Dropout(rate=dropout)(step)\n",
        "if layer>=2:\n",
        "  step=tf.keras.layers.Dense(256,activation='relu')(step)\n",
        "  if dropout!=0:\n",
        "      step=tf.keras.layers.Dropout(rate=dropout)(step)\n",
        "if layer>=1:\n",
        "  step=tf.keras.layers.Dense(64,activation='relu')(step)\n",
        "  if dropout!=0:\n",
        "      step=tf.keras.layers.Dropout(rate=dropout)(step)\n",
        "\n",
        "# Output layer for binary classification\n",
        "pred = Dense(1, activation='sigmoid')(step)\n",
        "\n",
        "model=tf.keras.Model(inputs=inputs,outputs=pred)\n",
        "\n",
        "# Define early stopping\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Define learning rate reduction\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.1,\n",
        "    patience=3,\n",
        "    verbose=1,\n",
        "    min_lr=lr\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.Adam(lr=lr),\n",
        "    metrics=[precision_metric]\n",
        ")\n",
        "model.summary()\n",
        "\n",
        "# Fit the model with early stopping and learning rate reduction\n",
        "history = model.fit(\n",
        "    [train_input_ids, train_input_masks, train_segment_ids],\n",
        "    train_labels,\n",
        "    epochs=epochs,\n",
        "    batch_size=32,\n",
        "    validation_data=([val_input_ids, val_input_masks, val_segment_ids], val_labels),\n",
        "    callbacks=[early_stopping, reduce_lr]\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "CYoMB0IbiE23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict probabilities for training and validation data\n",
        "y_train_prob = model.predict([train_input_ids, train_input_masks, train_segment_ids])\n",
        "y_val_prob = model.predict([val_input_ids, val_input_masks, val_segment_ids])\n",
        "\n",
        "# Convert probabilities to binary predictions using a threshold (0.5)\n",
        "y_train_pred = [1 if x > 0.5 else 0 for x in y_train_prob]\n",
        "y_val_pred = [1 if x > 0.5 else 0 for x in y_val_prob]\n",
        "\n",
        "# Calculate and print accuracy\n",
        "train_accuracy = int(100 * accuracy_score(train_labels, y_train_pred))\n",
        "val_accuracy = int(100 * accuracy_score(val_labels, y_val_pred))\n",
        "\n",
        "print(\"Training Accuracy : {0}%\".format(train_accuracy))\n",
        "print(\"Test Accuracy : {0}%\\n\".format(val_accuracy))\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix,auc\n",
        "\n",
        "# Generate and print classification report\n",
        "classification_rep = classification_report(val_labels, y_val_pred)\n",
        "print(classification_rep)\n",
        "\n",
        "# Generate and print confusion matrix\n",
        "confusion = confusion_matrix(val_labels, y_val_pred)\n",
        "print(confusion)"
      ],
      "metadata": {
        "id": "xNSdbTG8NUjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet"
      ],
      "metadata": {
        "id": "aaZv2D3TPJ7l"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9aGFytRHQMw"
      },
      "source": [
        "Custom Data Loader for keras models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bTMTsq1zWrH"
      },
      "source": [
        "train_labels = tf.convert_to_tensor(data_train['class'], dtype=tf.int64)\n",
        "\n",
        "def generateTrainingData(dataset, bs):\n",
        "\n",
        "  y_batch = []\n",
        "  x_batch_pic=[]\n",
        "  while True:\n",
        "\n",
        "    for i in range(math.ceil(dataset.shape[0]/bs)):\n",
        "\n",
        "        y_batch=train_labels[i*bs:min(i*bs+bs,train_labels.shape[0])]\n",
        "\n",
        "        for j in range(i*bs,min(i*bs+bs,data_train.shape[0])):\n",
        "          try:\n",
        "            img = PIL.Image.open('/content/memotion_dataset_7k/images/'+str(dataset['image'][j]))\n",
        "          except:\n",
        "            img = PIL.Image.open('/content/drive/My Drive/2000_data/'+str(dataset['image'][j]))\n",
        "\n",
        "          img=img.resize((256,256))\n",
        "          try:\n",
        "            img = np.asarray( img, dtype='uint8' )\n",
        "          except SystemError:\n",
        "            img = np.asarray( img.getdata(), dtype='uint8' )\n",
        "\n",
        "          if len(img.shape)<3:\n",
        "            img=img[:,:,np.newaxis]\n",
        "\n",
        "          if img.shape[2]<=2:\n",
        "            img=cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "          if img.shape[2]>3:\n",
        "            img=cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)\n",
        "\n",
        "          if len(img.shape)>3 or img.shape[2]!=3:\n",
        "            raise ValueError(str(row['image'])+\" \"+str(img.shape)+\"has a problem\")\n",
        "\n",
        "\n",
        "          img=img/255\n",
        "          x_batch_pic.append(img)\n",
        "\n",
        "\n",
        "        yield np.array(x_batch_pic),y_batch\n",
        "\n",
        "        y_batch = []\n",
        "        x_batch_pic=[]\n",
        "\n",
        "def generatePredictionData(dataset, bs):\n",
        "\n",
        "  x_batch = []\n",
        "  #y_batch = []\n",
        "  x_batch_pic=[]\n",
        "  while True:\n",
        "\n",
        "    for i in (range(math.ceil(dataset.shape[0]/bs))):\n",
        "\n",
        "\n",
        "        for j in range(i*bs,min(i*bs+bs,data_val.shape[0])):\n",
        "          try:\n",
        "            img = PIL.Image.open('/content/memotion_dataset_7k/images/'+str(dataset['image'][j]))\n",
        "          except:\n",
        "            img = PIL.Image.open('/content/drive/My Drive/2000_data/'+str(dataset['image'][j]))\n",
        "\n",
        "          img=img.resize((256,256))\n",
        "          try:\n",
        "            img = np.asarray( img, dtype='uint8' )\n",
        "          except SystemError:\n",
        "            img = np.asarray( img.getdata(), dtype='uint8' )\n",
        "\n",
        "          if len(img.shape)<3:\n",
        "            img=img[:,:,np.newaxis]\n",
        "\n",
        "          if img.shape[2]<=2:\n",
        "            img=cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "          if img.shape[2]>3:\n",
        "            img=cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)\n",
        "\n",
        "          if len(img.shape)>3 or img.shape[2]!=3:\n",
        "            raise ValueError(str(row['image'])+\" \"+str(img.shape)+\"has a problem\")\n",
        "\n",
        "          img=img/255\n",
        "          x_batch_pic.append(img)\n",
        "\n",
        "\n",
        "\n",
        "        yield np.array(x_batch_pic)#, np.array(y_batch)\n",
        "\n",
        "        x_batch = []\n",
        "        #y_batch = []\n",
        "        x_batch_pic=[]\n",
        "\n",
        "def generateTestPredictionData(dataset, bs):\n",
        "\n",
        "  x_batch = []\n",
        "  #y_batch = []\n",
        "  x_batch_pic=[]\n",
        "  while True:\n",
        "\n",
        "    for i in (range(math.ceil(dataset.shape[0]/bs))):\n",
        "\n",
        "        for j in range(i*bs,min(i*bs+bs,data_test.shape[0])):\n",
        "          try:\n",
        "            img = PIL.Image.open('/content/memotion_dataset_7k/images/'+str(dataset['image'][j]))\n",
        "          except:\n",
        "            img = PIL.Image.open('/content/2000_data/'+str(dataset['image'][j]))\n",
        "\n",
        "          img=img.resize((256,256))\n",
        "          try:\n",
        "            img = np.asarray( img, dtype='uint8' )\n",
        "          except SystemError:\n",
        "            img = np.asarray( img.getdata(), dtype='uint8' )\n",
        "\n",
        "          if len(img.shape)<3:\n",
        "            img=img[:,:,np.newaxis]\n",
        "\n",
        "          if img.shape[2]<=2:\n",
        "            img=cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "          if img.shape[2]>3:\n",
        "            img=cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)\n",
        "\n",
        "          if len(img.shape)>3 or img.shape[2]!=3:\n",
        "            raise ValueError(str(row['image'])+\" \"+str(img.shape)+\"has a problem\")\n",
        "\n",
        "          img=img/255\n",
        "\n",
        "          x_batch_pic.append(img)\n",
        "\n",
        "        #print(dataset.iloc[i*bs]['text'])\n",
        "\n",
        "        yield np.array(x_batch_pic)#, np.array(y_batch)\n",
        "\n",
        "        x_batch = []\n",
        "        #y_batch = []\n",
        "        x_batch_pic=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83dIMaDEpMlb"
      },
      "source": [
        "Building Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VO38pFOfobpl"
      },
      "source": [
        "image_inputs = Input(shape=(256, 256, 3), name=\"meme_images\")\n",
        "\n",
        "image_step = tf.keras.applications.ResNet50(include_top=False, weights='imagenet',\n",
        "                                            input_tensor=None, input_shape=(256, 256, 3), pooling=False, classes=2)(image_inputs)\n",
        "\n",
        "image_step = GlobalAveragePooling2D()(image_step)\n",
        "image_step = Dense(768, activation='relu')(image_step)\n",
        "image_step = BatchNormalization()(image_step)\n",
        "\n",
        "h = Dense(256, activation='relu')(image_step)\n",
        "pred = Dense(1, activation='sigmoid')(h)\n",
        "\n",
        "model = Model(inputs=image_inputs, outputs=pred)\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(lr=2e-5, clipnorm=1.),\n",
        "              metrics=[f1,'accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Define Early Stopping and Reduce LR callbacks\n",
        "early_stopping = EarlyStopping(patience=5, restore_best_weights=True, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4z_-R6TNpTTZ"
      },
      "source": [
        "Keras Callbacks to simplify model saving"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vr8Ws4bYohSl"
      },
      "source": [
        "class Saver(tf.keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.score = 0\n",
        "        self.epoch_number = 0\n",
        "\n",
        "    def on_epoch_end(self, logs={}, *args):\n",
        "        test_gen = generatePredictionData(data_val, 32)\n",
        "        predict = np.argmax(self.model.predict(test_gen, steps=data_val.shape[0] // 32 + 1, verbose=1), axis=1)\n",
        "        accuracy = accuracy_score(data_val['class'].astype('int')[:, np.newaxis], predict[:, np.newaxis])\n",
        "        print(f\"Validation Accuracy: {accuracy}\")\n",
        "\n",
        "        self.model.save_weights('/content/drive/My Drive/Memotion/model_save_memo/imageC-2-{}.h5'.format(self.epoch_number))\n",
        "        self.epoch_number = self.epoch_number + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_d_owX0Iopu2"
      },
      "source": [
        "Begin Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8wh6B2OorQm"
      },
      "source": [
        "import math\n",
        "gen = generateTrainingData(data_train, 32)\n",
        "model.fit_generator(\n",
        "    gen,\n",
        "    steps_per_epoch=data_train.shape[0] // 32 + 1,\n",
        "    epochs=10,\n",
        "    max_queue_size=10,\n",
        "    workers=1,\n",
        "    shuffle=False,\n",
        "    callbacks=[Saver(), early_stopping, reduce_lr]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_7fL2expZvR"
      },
      "source": [
        "Test Validation Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSpm7mjwow_h"
      },
      "source": [
        "test_gen = generatePredictionData(data_val, 32)  # Replace with your data generator for validation data\n",
        "predict = model.predict(test_gen, steps=data_val.shape[0] // 32 + 1, verbose=1)\n",
        "y_val_true = data_val['class'].astype('int')[:, np.newaxis]\n",
        "y_val_pred = np.argmax(predict, axis=1)\n",
        "print(\"Validation Classification Report:\")\n",
        "print(classification_report(y_val_true, y_val_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MultiModal"
      ],
      "metadata": {
        "id": "TmXEa2tVb9ni"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HB0JSZDrqLy3"
      },
      "source": [
        "Setting maximum sequence length for the inputs to RoBERTa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6CMtdRlqLy4"
      },
      "source": [
        "\n",
        "max_seq_length=0\n",
        "for i in tqdm(range(data_train.shape[0])):\n",
        "    max_seq_length=max(len(data_train.iloc[i,0].split()),max_seq_length)\n",
        "max_seq_length=max_seq_length+2\n",
        "print(max_seq_length)\n",
        "\n",
        "\n",
        "# output :\n",
        "# 201"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAvqmfLeqLy4"
      },
      "source": [
        "Textual data processing function to prepare meme overlay text for input to Roberta Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_examples_to_features(sentences, label_list, max_seq_length, tokenizer):\n",
        "    input_ids, input_masks, segment_ids, labels = [], [], [], []\n",
        "    for index in tqdm_notebook(range(len(sentences)), desc=\"Converting examples to features\"):\n",
        "        sentence = sentences[index]\n",
        "        if sentence == '':\n",
        "            sentence = \" \"\n",
        "        # inputs = tokenizer.encode_plus(sentence, max_length=max_seq_length, pad_to_max_length=True)\n",
        "        inputs = tokenizer.encode_plus(\n",
        "            sentence,\n",
        "            add_special_tokens=True,  # Add [CLS] and [SEP] tokens\n",
        "            max_length=max_seq_length,# Specify the maximum length of the tokens\n",
        "            pad_to_max_length=True,   # Pad shorter sequences to max length\n",
        "            return_token_type_ids=True,  # Return segment IDs\n",
        "            return_attention_mask=True,  # Return attention mask\n",
        "          )\n",
        "        input_id = inputs['input_ids']\n",
        "        input_mask = inputs['attention_mask']\n",
        "        segment_id = inputs['token_type_ids']\n",
        "        label = label_list[index]\n",
        "        input_ids.append(input_id)\n",
        "        input_masks.append(input_mask)\n",
        "        segment_ids.append(segment_id)\n",
        "        labels.append(label)\n",
        "    return (\n",
        "        np.array(input_ids),\n",
        "        np.array(input_masks),\n",
        "        np.array(segment_ids)\n",
        "        # np.array(labels)\n",
        "    )"
      ],
      "metadata": {
        "id": "w2et5zaTqLy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_process_image(image_path, target_size=(256, 256)):\n",
        "    try:\n",
        "        img = PIL.Image.open(image_path)\n",
        "    except:\n",
        "        img = PIL.Image.open('/content/drive/My Drive/2000_data/' + image_path)\n",
        "\n",
        "    img = img.resize(target_size)\n",
        "    try:\n",
        "        img = np.asarray(img, dtype='uint8')\n",
        "    except SystemError:\n",
        "        img = np.asarray(img.getdata(), dtype='uint8')\n",
        "\n",
        "    if len(img.shape) < 3:\n",
        "        img = img[:, :, np.newaxis]\n",
        "\n",
        "    if img.shape[2] <= 2:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "    if img.shape[2] > 3:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)\n",
        "\n",
        "    if len(img.shape) > 3 or img.shape[2] != 3:\n",
        "        raise ValueError(image_path + \" \" + str(img.shape) + \" has a problem\")\n",
        "\n",
        "    img = img / 255\n",
        "\n",
        "    return img\n"
      ],
      "metadata": {
        "id": "w5vMc50ruRYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = tf.convert_to_tensor(data_train['class'], dtype=tf.int64)\n",
        "\n",
        "tokenizer=RobertaTokenizer.from_pretrained('roberta-base')\n",
        "\n",
        "data_train=data_train.reset_index(drop=True)\n",
        "data_val=data_val.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "sS25gkRXyqX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5t6Ug5Ssqy3N"
      },
      "source": [
        "Custom Data Loader for keras models used latter in the notebook"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generateTrainingData(dataset, bs):\n",
        "    y_batch, x_batch_tokens, x_batch_masks, x_batch_segments, x_batch_pic = [], [], [], [], []\n",
        "\n",
        "    x_batch_tokens, x_batch_masks, x_batch_segments = convert_examples_to_features(\n",
        "                dataset['text'],\n",
        "                dataset['class'],\n",
        "                max_seq_length,\n",
        "                tokenizer)\n",
        "    for i in range(math.ceil(dataset.shape[0] / bs)):\n",
        "        a = i * bs\n",
        "        b = min(i * bs + bs, dataset.shape[0])\n",
        "        y_batch = train_labels[a:b]\n",
        "        for j in range(a, b):\n",
        "            image_path = '/content/memotion_dataset_7k/images/' + str(dataset['image'][j])\n",
        "            img = load_and_process_image(image_path)\n",
        "            x_batch_pic.append(img)\n",
        "        yield [np.array(x_batch_tokens[a:b]), np.array(x_batch_masks[a:b]), np.array(x_batch_segments[a:b]), np.array(x_batch_pic)], np.array(y_batch)\n",
        "        y_batch, x_batch_pic = [], []\n",
        "\n",
        "def generateTestData(dataset, bs):\n",
        "    x_batch_tokens, x_batch_masks, x_batch_segments, x_batch_pic = [], [], [], [], []\n",
        "    while True:\n",
        "        for i in range(math.ceil(dataset.shape[0] / bs)):\n",
        "            a = i * bs\n",
        "            b = min(i * bs + bs, dataset.shape[0])\n",
        "\n",
        "            x_batch_tokens, x_batch_masks, x_batch_segments = convert_examples_to_features(\n",
        "                dataset[a: b]['text'],\n",
        "                y_batch,\n",
        "                max_seq_length,\n",
        "                tokenizer\n",
        "            )\n",
        "\n",
        "            for j in range(a, b):\n",
        "                image_path = '/content/memotion_dataset_7k/images/' + str(dataset['image'][j])\n",
        "                img = load_and_process_image(image_path)\n",
        "\n",
        "                x_batch_pic.append(img)\n",
        "\n",
        "            yield [np.array(x_batch_tokens), np.array(x_batch_masks), np.array(x_batch_segments), np.array(x_batch_pic)]\n",
        "            x_batch_tokens, x_batch_masks, x_batch_segments, x_batch_pic = [], [], [], [], []"
      ],
      "metadata": {
        "id": "614eSJ1BuNd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PSFa8rX4O2s"
      },
      "source": [
        "##Early Fusion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvYOom6zWcn"
      },
      "source": [
        "from tensorflow.keras.layers import Input,Dense,Bidirectional,Conv2D,MaxPooling2D,Flatten,concatenate,GlobalAveragePooling2D,BatchNormalization,Lambda,Add,Multiply\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam,SGD\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.metrics import f1_score,accuracy_score\n",
        "\n",
        "\n",
        "token_inputs = tf.keras.layers.Input(shape=(None,), name='word_inputs', dtype=tf.int32)\n",
        "mask_inputs = tf.keras.layers.Input(shape=(None,), name='mask_inputs', dtype=tf.int32)\n",
        "seg_inputs = tf.keras.layers.Input(shape=(None,), name='seg_inputs', dtype=tf.int32)\n",
        "\n",
        "image_inputs=tf.keras.layers.Input(shape=(256,256,3),name=\"meme_images\")\n",
        "\n",
        "\n",
        "inputs=[token_inputs,mask_inputs,seg_inputs,image_inputs]\n",
        "text_inputs=[token_inputs,mask_inputs,seg_inputs]\n",
        "\n",
        "\n",
        "transformer_outputs= TFRobertaModel.from_pretrained('roberta-base')(text_inputs)[0][:,0,:]\n",
        "transformer_outputs=tf.keras.layers.BatchNormalization()(transformer_outputs)\n",
        "\n",
        "image_step=tf.keras.applications.ResNet50(include_top=False, weights='imagenet', input_tensor=None, input_shape=(256,256,3), pooling=False, classes=3,)(image_inputs)\n",
        "image_step=GlobalAveragePooling2D()(image_step)\n",
        "image_step=tf.keras.layers.Dense(768,activation='relu')(image_step)\n",
        "image_step=tf.keras.layers.BatchNormalization()(image_step)\n",
        "\n",
        "\n",
        "\n",
        "concat_output=concatenate([transformer_outputs,image_step],axis=1)\n",
        "concat_output=tf.keras.layers.LayerNormalization()(concat_output)\n",
        "\n",
        "h=Dense(256,activation='relu')(concat_output)\n",
        "pred = Dense(1, activation='sigmoid')(h)\n",
        "\n",
        "model=Model(inputs=inputs,outputs=pred)\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(lr=2e-5, clipnorm=1.),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Define Early Stopping and Reduce LR callbacks\n",
        "early_stopping = EarlyStopping(patience=5, restore_best_weights=True, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBEwtp8Y4Vip"
      },
      "source": [
        "##Gated MultiModal Unit (GMU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsCVD0Sc4WUn"
      },
      "source": [
        "from tensorflow.keras.layers import Input,Dense,Bidirectional,Conv2D,MaxPooling2D,Flatten,concatenate,GlobalAveragePooling2D,BatchNormalization,Lambda,Add,Multiply\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam,SGD\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.metrics import f1_score,accuracy_score\n",
        "\n",
        "token_inputs = tf.keras.layers.Input(shape=(None,), name='word_inputs', dtype=tf.int32)\n",
        "mask_inputs = tf.keras.layers.Input(shape=(None,), name='mask_inputs', dtype=tf.int32)\n",
        "seg_inputs = tf.keras.layers.Input(shape=(None,), name='seg_inputs', dtype=tf.int32)\n",
        "\n",
        "image_inputs=tf.keras.layers.Input(shape=(256,256,3),name=\"meme_images\")\n",
        "\n",
        "\n",
        "inputs=[token_inputs,mask_inputs,seg_inputs,image_inputs]\n",
        "text_inputs=[token_inputs,mask_inputs,seg_inputs]\n",
        "\n",
        "\n",
        "transformer_outputs= TFRobertaModel.from_pretrained('roberta-base')(text_inputs)[0][:,0,:]\n",
        "transformer_outputs=tf.keras.layers.BatchNormalization()(transformer_outputs)\n",
        "\n",
        "image_step=tf.keras.applications.ResNet50(include_top=False, weights='imagenet', input_tensor=None, input_shape=(256,256,3), pooling=False, classes=3,)(image_inputs)\n",
        "image_step=GlobalAveragePooling2D()(image_step)\n",
        "image_step=tf.keras.layers.Dense(768,activation='relu')(image_step)\n",
        "image_step=tf.keras.layers.BatchNormalization()(image_step)\n",
        "\n",
        "concat_output=concatenate([transformer_outputs,image_step],axis=1)\n",
        "concat_output=tf.keras.layers.LayerNormalization()(concat_output)\n",
        "\n",
        "# Gated Multimodal Block - Begin\n",
        "hv=Dense(768,activation='tanh')(image_step)\n",
        "ht=Dense(768,activation='tanh')(transformer_outputs)\n",
        "z=Dense(768,activation='sigmoid')(concat_output)\n",
        "h=Add()([Multiply()([z,hv]),Multiply()([Lambda(lambda x: 1. - x)(z),ht])])\n",
        "# Gated Multimodal Block - End\n",
        "\n",
        "\n",
        "h=Dense(256,activation='relu')(h)\n",
        "pred = Dense(1, activation='sigmoid')(h)\n",
        "\n",
        "model=Model(inputs=inputs,outputs=pred)\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(lr=2e-5, clipnorm=1.),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Define Early Stopping and Reduce LR callbacks\n",
        "early_stopping = EarlyStopping(patience=5, restore_best_weights=True, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Eval"
      ],
      "metadata": {
        "id": "T4tumfuo6agu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTOZwrPLfOJP"
      },
      "source": [
        "Keras Callbacks to simplify model saving"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bs = 32"
      ],
      "metadata": {
        "id": "p4zNIVsI81_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mqDdLJ5fOJQ"
      },
      "source": [
        "class Saver(tf.keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.score = 0\n",
        "        self.epoch_number = 0\n",
        "\n",
        "    def on_epoch_end(self, logs={}, *args):\n",
        "        test_gen = generatePredictionData(data_val, bs)\n",
        "        predict = np.argmax(self.model.predict(test_gen, steps=data_val.shape[0] // bs + 1, verbose=1), axis=1)\n",
        "        accuracy = accuracy_score(data_val['class'].astype('int')[:, np.newaxis], predict[:, np.newaxis])\n",
        "        print(f\"Validation Accuracy: {accuracy}\")\n",
        "\n",
        "        self.model.save_weights('/content/drive/My Drive/Memotion/model_save_memo/imageC-2-{}.h5'.format(self.epoch_number))\n",
        "        self.epoch_number = self.epoch_number + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdNg8DxufOJQ"
      },
      "source": [
        "Begin Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZK-Oj_bfOJQ"
      },
      "source": [
        "import math\n",
        "gen = generateTrainingData(data_train, bs)\n",
        "model.fit_generator(\n",
        "    gen,\n",
        "    steps_per_epoch=data_train.shape[0] // bs + 1,\n",
        "    epochs=10,\n",
        "    max_queue_size=10,\n",
        "    workers=1,\n",
        "    shuffle=False,\n",
        "    callbacks=[Saver(), early_stopping, reduce_lr]\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5v3eJ8-fOJR"
      },
      "source": [
        "Test Validation Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrMBy0NKfOJR"
      },
      "source": [
        "test_gen = generateTestData(data_val, bs)  # Replace with your data generator for validation data\n",
        "predict = model.predict(test_gen, steps=data_val.shape[0] // bs + 1, verbose=1)\n",
        "y_val_true = data_val['class'].astype('int')[:, np.newaxis]\n",
        "y_val_pred = np.argmax(predict, axis=1)\n",
        "print(\"Validation Classification Report:\")\n",
        "print(classification_report(y_val_true, y_val_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M3strxhEYSHr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}